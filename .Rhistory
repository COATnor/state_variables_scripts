## clear workspace
rm(list = ls())
## load libraries, missing packages will be installed
if (!require("remotes")) install.packages("remotes")
if (!require("ckanr")) remotes::install_github("ropensci/ckanr"); library("ckanr")
if (!require("tidyverse")) install.packages("tidyverse"); library("tidyverse")
if (!require("lubridate")) install.packages("tidyverse"); library("lubridate")
## setup the connection to the data portal
COAT_url <- "https://data.coat.no" # write here the url to the COAT data portal
COAT_key <- Sys.getenv("API_coat") # write here your API key if you are a registered user, continue without API key if you are not registered
ckanr_setup(url = COAT_url, key = COAT_key) # set up the ckanr-API
## list all datasets available on the COAT data portal
package_list()
## serach for your dataset
name <- "v_air_temperature_snowbed_v5" # write here the name including the version of the dataset you want to download
version <- "5" # write here the version of the dataset
pkg <- package_search(q = list(paste("name:", name, sep = "")), fq = list(paste("version:", version, sep = "")), include_private = TRUE)$results[[1]] # search for the dataset and save the results
urls <- pkg$resources %>% sapply("[[", "url") # get the urls to the files included in the dataset
filenames <- pkg$resources %>% sapply("[[", "name") # get the filenames
## specify if the downloaded files should be saved to your computer or imported into R
store <- "session" # "session" (imports data into R) or "disk" (saves the file to you computer)
meta <- grep("readme|aux|coordinates|metadata", filenames)
urls2 <- urls[-meta]
filenames2 <- filenames[-meta]
## download aux file
aux_id <- grep("aux", filenames)
filenames[aux_id]
aux_url <- urls[aux_id]
aux <- ckan_fetch(aux_url,
store = store,
sep = ";",
header = TRUE,
format = "txt"
)
head(aux)
## download all files of the dataset
mylist <- c() # empty object for the files
for (i in 1:length(filenames2)) {
mylist[[i]] <- ckan_fetch(urls2[i],
store = store,
path = paste(dest_dir, name, filenames2[i], sep = "/"),
sep = ";",
header = TRUE,
format = "txt"
)
mylist[[i]]$t_year <- gsub("V_air_temperature_snowbed_|.txt", "", filenames2[i])  # needs to be modified to match other datasets
}
years <- unlist(map(mylist, function(x) unique(x$t_year)))
snowmelt <- c()
state_var_names <- c()
for (i in 1:length(years)) {
## calculate snowmelt (first day with daily mean temp over 1.1 deg C)
snowmelt[[i]] <- mylist[[i]] %>%
group_by(sn_region, sn_locality, sn_section, sc_type_of_sites_ecological, sn_site, sn_plot, t_year, t_date) %>%
summarise(mean_temp = mean(as.numeric(v_temperature), na.rm = TRUE)) %>%
filter(mean_temp > 1.1) %>%
filter(grepl(years[i], t_date)) %>%
group_by(sn_region, sn_locality, sn_section, sc_type_of_sites_ecological, sn_site, sn_plot, t_year) %>%
summarise(t_date_snowmelt = min(t_date))
## add sites where the snow just melted before the logger was collected
## temperature didn't start to rise for these loggers and the snowmelt date will be set to the date when the logger was collected (one day after the last registered date)
missing <- unique(mylist[[i]]$sn_site)[!unique(mylist[[i]]$sn_site) %in% unique(snowmelt[[i]]$sn_site)]
if (length(missing) > 0) {
add <- mylist[[i]][mylist[[i]]$sn_site %in% missing, 1:7] %>%
group_by(sn_region, sn_locality, sn_section, sc_type_of_sites_ecological, sn_site, sn_plot) %>%
summarise(t_date_snowmelt = max(t_date)) %>%
mutate(t_date_snowmelt = as.character(ymd(t_date_snowmelt) + days(1))) %>%
add_column(t_year = years[i])
snowmelt[[i]] <- rbind(snowmelt[[i]], add)
}
## add sites where the logger was not found/did not work with NA for t_snowmelt_date
pot.sites <- aux$sn_site[is.na(aux$year_last) | aux$year_last >= years[i]]
missing <- pot.sites[!pot.sites %in% snowmelt[[i]]$sn_site]
if (length(missing) > 0) {
add <- aux %>%
filter(sn_site %in% missing) %>%
select(sn_region, sn_locality, sn_section, sn_site) %>%
add_column(sc_type_of_sites_ecological = "snowbed", sn_plot = 2, t_date_snowmelt = NA, t_year = years[i])  # needs to be modified to match other datasets
snowmelt[[i]] <- rbind(snowmelt[[i]], add)
}
snowmelt[[i]] <- arrange(snowmelt[[i]], sn_site)
## set snow melt date to NA if logger stopped logging too early
if (years[i] == "2019") snowmelt[[i]]$t_date_snowmelt[snowmelt[[i]]$sn_site == "vj_be_sn_11"] <- NA
## correct snowmelt (after inspecting calculated snow melt dates visually)
if (years[i] == "2023") snowmelt[[i]]$t_date_snowmelt[snowmelt[[i]]$sn_site == "ko_kj_sn_8"] <- "2023-05-26"
## save the file to a temporary directory (necessary for uploading it)
state_var_names[i] <- paste0("C1_snow_melt_date_logger_varanger_snowbeds_", years[i], ".txt")
write.table(snowmelt[[i]], paste(tempdir(), state_var_names[i], sep = "/"), row.names = FALSE, sep = ";")
print(paste("state variable calculated and saved to temporary directory:", state_var_names[i]))
}
xx <- snowmelt[[i]]
View(xx)
## check if snow melt date and year match
snowmelt %>% do.call(rbind, .) %>%
filter(t_year != year(ymd(t_date_snowmelt)))
year <- 2023
year <- 2024
x <- which(years == year)
snowmelt_x <- snowmelt[[x]]
myfile_x <- mylist[[x]]
snowbeds <- unique(snowmelt_x$sn_site)
for (i in snowbeds) {
## prepare snowmelt data
dat <- snowmelt_x %>%
subset(sn_site == i) %>%
mutate(t_date_snowmelt = ymd(t_date_snowmelt))
if (is.na(dat$t_date_snowmelt)) next
## prepare temperature data
temp_dat <- myfile_x %>%
subset(sn_site == i) %>%
mutate(t_date <- ymd(t_date)) %>%
subset(t_date > ymd(paste0(year, "04_30")))
## plot temperature data and snowmelt date
plot(v_temperature ~ ymd_hms(t_bintime), dat = temp_dat, type = "l", lwd = 1, xlab = "", main = paste(i, year))
if (!is.na(dat$t_date_snowmelt)) abline(v = ymd_hms(paste(dat$t_date_snowmelt, "14:00:00")), col = "red", lwd = 2)
}
years
xx <- snowmelt[[10]]
View(xx)
year <- 2019
x <- which(years == year)
snowmelt_x <- snowmelt[[x]]
myfile_x <- mylist[[x]]
snowbeds <- unique(snowmelt_x$sn_site)
for (i in snowbeds) {
## prepare snowmelt data
dat <- snowmelt_x %>%
subset(sn_site == i) %>%
mutate(t_date_snowmelt = ymd(t_date_snowmelt))
if (is.na(dat$t_date_snowmelt)) next
## prepare temperature data
temp_dat <- myfile_x %>%
subset(sn_site == i) %>%
mutate(t_date <- ymd(t_date)) %>%
subset(t_date > ymd(paste0(year, "04_30")))
## plot temperature data and snowmelt date
plot(v_temperature ~ ymd_hms(t_bintime), dat = temp_dat, type = "l", lwd = 1, xlab = "", main = paste(i, year))
if (!is.na(dat$t_date_snowmelt)) abline(v = ymd_hms(paste(dat$t_date_snowmelt, "14:00:00")), col = "red", lwd = 2)
}
## serach for your dataset
state_name <- "c1_snow_melt_date_logger_varanger_v3" # write here the name including the version of the state variable you want to add data to
state_version <- "3" # write here the version of the state variable
pkg_state <- package_search(q = list(paste("name:", state_name, sep = "")), fq = list(paste("version:", state_version, sep = "")), include_private = TRUE, include_drafts = TRUE)$results[[1]] # search for the dataset and save the results
filenames_state <- pkg_state$resources %>% sapply("[[", "name") # get the filenames
filenames_state # are there any files
state_var_names
paste(tempdir(), i
)
i = 10
paste(tempdir(), i)
state_var_names[10, 15]
state_var_names[c(10, 15)]
# upload the files
for (i in state_var_names[c(10, 15)]) {
resource_create(
package_id = pkg_state$id,
description = NULL,
upload = paste(tempdir(), i, sep = "/"),
name = i,
http_method = "POST"
)
}
